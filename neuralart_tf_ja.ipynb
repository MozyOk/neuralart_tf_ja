{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Algorithm of Arctic Style 画風変換\n",
    "# Tensor Flowで実装する\n",
    "\n",
    "# 長文説明バージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGの学習済みの重みを利用します。その為、MATLABのmat形式で配布されているファイルをダウンロードします。\n",
    "URL: http://www.vlfeat.org/matconvnet/pretrained/  \n",
    "(VGG-VDモデルの、imagenet-vgg-verydeep-19.matをダウンロードします。)  \n",
    "今回は、ダウンロードしたファイルを  \n",
    "`[カレントディレクトリ]>[models]`  \n",
    "に保存しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG_MODEL = \"models/imagenet-vgg-verydeep-19.mat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画風変換に利用する画像を設定していきます。  \n",
    "スタイル画像の特徴をコンテンツ画像に適用していき、その結果が生成画像として出力されます。  \n",
    "また、生成画像は最適化回数ごとに出力されますので、ディレクトリを指定します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_IMG = 'images/SetoBridge.jpg'  # コンテンツ画像\n",
    "STYLE_IMG = 'images/StarryNight.jpg'  # スタイル画像\n",
    "\n",
    "OUTPUT_DIR = 'results'  # 生成画像ディレクトリ\n",
    "OUTPUT_IMG = 'result.png'  # 生成画像ファイル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGは600×300×3の画像を想定しているので、それぞれのサイズを設定する。  \n",
    "平均値をゼロにするため、VGGの訓練データの平均画素値[123.68, 116.779, 103.939]を引かなければならない。(その為、平均画素値はVGGモデルにより異なる。)　　\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_W = 800\n",
    "IMAGE_H = 500\n",
    "#  入力画像から平均画素値を引くための定数(reshapeでそのまま引けるようにする)\n",
    "MEAN_VALUES = np.array([123, 117, 104]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_net(ntype, nin, rwb=None):\n",
    "    \"\"\"\n",
    "    ネットワークの各層をTensorFlowで定義する関数\n",
    "    : param ntype: ネットワークの層のタイプ(ここでは、畳み込み層もしくは、プーリング層)\n",
    "    : param nin: 前の層\n",
    "    : param rwb: VGGの最適化された値\n",
    "    \"\"\"\n",
    "    if ntype == 'conv':\n",
    "        return tf.nn.relu(tf.nn.conv2d(nin, rwb[0], strides=[1, 1, 1, 1], padding='SAME') + rwb[1])\n",
    "    elif ntype == 'pool':\n",
    "        return tf.nn.avg_pool(nin, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weight_bias(vgg_layers, i):\n",
    "    \"\"\"\n",
    "    VGGの各層の最適化された重みとバイアスを取得する関数\n",
    "    : param vgg_layers: ネットワークの層\n",
    "    : param i:\n",
    "    \"\"\"\n",
    "    weights = vgg_layers[i][0][0][2][0][0]\n",
    "    weights = tf.constant(weights)\n",
    "    bias = vgg_layers[i][0][0][2][0][1]\n",
    "    bias = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vgg19(path):\n",
    "    \"\"\"\n",
    "    TensorFlowでVGGネットワークを構成する関数\n",
    "    : param path: VGGの学習済みモデルのファイルのパス\n",
    "    \"\"\"\n",
    "    net = {}\n",
    "    vgg_rawnet = scipy.io.loadmat(path)\n",
    "    vgg_layers = vgg_rawnet['layers'][0]\n",
    "    net['input'] = tf.Variable(np.zeros((1, IMAGE_H, IMAGE_W, 3)).astype('float32'))\n",
    "    net['conv1_1'] = build_net('conv',net['input'],get_weight_bias(vgg_layers,0))\n",
    "    net['conv1_2'] = build_net('conv',net['conv1_1'],get_weight_bias(vgg_layers,2))\n",
    "    net['pool1']   = build_net('pool',net['conv1_2'])\n",
    "    net['conv2_1'] = build_net('conv',net['pool1'],get_weight_bias(vgg_layers,5))\n",
    "    net['conv2_2'] = build_net('conv',net['conv2_1'],get_weight_bias(vgg_layers,7))\n",
    "    net['pool2']   = build_net('pool',net['conv2_2'])\n",
    "    net['conv3_1'] = build_net('conv',net['pool2'],get_weight_bias(vgg_layers,10))\n",
    "    net['conv3_2'] = build_net('conv',net['conv3_1'],get_weight_bias(vgg_layers,12))\n",
    "    net['conv3_3'] = build_net('conv',net['conv3_2'],get_weight_bias(vgg_layers,14))\n",
    "    net['conv3_4'] = build_net('conv',net['conv3_3'],get_weight_bias(vgg_layers,16))\n",
    "    net['pool3']   = build_net('pool',net['conv3_4'])\n",
    "    net['conv4_1'] = build_net('conv',net['pool3'],get_weight_bias(vgg_layers,19))\n",
    "    net['conv4_2'] = build_net('conv',net['conv4_1'],get_weight_bias(vgg_layers,21))\n",
    "    net['conv4_3'] = build_net('conv',net['conv4_2'],get_weight_bias(vgg_layers,23))\n",
    "    net['conv4_4'] = build_net('conv',net['conv4_3'],get_weight_bias(vgg_layers,25))\n",
    "    net['pool4']   = build_net('pool',net['conv4_4'])\n",
    "    net['conv5_1'] = build_net('conv',net['pool4'],get_weight_bias(vgg_layers,28))\n",
    "    net['conv5_2'] = build_net('conv',net['conv5_1'],get_weight_bias(vgg_layers,30))\n",
    "    net['conv5_3'] = build_net('conv',net['conv5_2'],get_weight_bias(vgg_layers,32))\n",
    "    net['conv5_4'] = build_net('conv',net['conv5_3'],get_weight_bias(vgg_layers,34))\n",
    "    net['pool5']   = build_net('pool',net['conv5_4'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_content_loss(p, x):\n",
    "    \"\"\"\n",
    "    コンテンツと出力の誤差\n",
    "    \"\"\"\n",
    "    M = p.shape[1]*p.shape[2]\n",
    "    N = p.shape[3]\n",
    "    loss = (1./(2* N**0.5 * M**0.5 )) * tf.reduce_sum(tf.pow((x - p),2))  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x, area, depth):\n",
    "    x1 = tf.reshape(x,(area,depth))\n",
    "    g = tf.matmul(tf.transpose(x1), x1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix_val(x, area, depth):\n",
    "    x1 = x.reshape(area,depth)\n",
    "    g = np.dot(x1.T, x1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_style_loss(a, x):\n",
    "    M = a.shape[1]*a.shape[2]\n",
    "    N = a.shape[3]\n",
    "    A = gram_matrix_val(a, M, N )\n",
    "    G = gram_matrix(x, M, N )\n",
    "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A),2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    \"\"\"\n",
    "    画像を読み込む関数\n",
    "    \"\"\"\n",
    "    image = scipy.misc.imread(path)\n",
    "    image = scipy.misc.imresize(image,(IMAGE_H,IMAGE_W))\n",
    "    image = image[np.newaxis,:,:,:] \n",
    "    image = image - MEAN_VALUES\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_image(path, image):\n",
    "    \"\"\"\n",
    "    生成された画像を保存する関数\n",
    "    \"\"\"\n",
    "    image = image + MEAN_VALUES\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG19モデルの作成\n",
    "net = build_vgg19(VGG_MODEL)\n",
    "# ホワイトノイズ\n",
    "noise_img = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, 3)).astype('float32')\n",
    "# 画像の読み込み\n",
    "content_img = read_image(CONTENT_IMG)\n",
    "style_img = read_image(STYLE_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "画風変換の出力を調節するにはここを変更\n",
    "\"\"\"\n",
    "# 各種パラメータの設定\n",
    "INI_NOISE_RATIO = 0.7 # ホワイトノイズの重み\n",
    "STYLE_STRENGTH = 500 # スタイルの強さ\n",
    "ITERATION = 5000 # 最適化回数\n",
    "\n",
    "# コンテンツ画像と出力画像で誤差を取る層\n",
    "CONTENT_LAYERS =[('conv4_2',1.)]\n",
    "# スタイル画像と出力画像で誤差を取る層\n",
    "STYLE_LAYERS=[('conv1_1',1.),('conv2_1',1.),('conv3_1',1.),('conv4_1',1.),('conv5_1',1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run([net['input'].assign(content_img)])\n",
    "cost_content = sum(map(lambda l,: l[1]*build_content_loss(sess.run(net[l[0]]) ,  net[l[0]]), CONTENT_LAYERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run([net['input'].assign(style_img)])\n",
    "cost_style = sum(map(lambda l: l[1]*build_style_loss(sess.run(net[l[0]]) ,  net[l[0]]), STYLE_LAYERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_total = cost_content + STYLE_STRENGTH * cost_style\n",
    "optimizer = tf.train.AdamOptimizer(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -8.90594292,   4.98616314,  23.42633438],\n",
       "         [  2.85777044,  21.7790432 ,  37.6257782 ],\n",
       "         [  7.12507439,   2.30034161,  16.07798004],\n",
       "         ..., \n",
       "         [ 15.64326286,  20.30531311,  35.65568161],\n",
       "         [ 14.09522915,   6.40278625,  41.16028595],\n",
       "         [  5.11479378,  18.35180473,  28.48310089]],\n",
       "\n",
       "        [[ -1.13934422,  23.13929176,  39.82580185],\n",
       "         [ 12.12512302,   9.65085411,  18.56409264],\n",
       "         [  0.45161247,   4.92058039,  22.86688042],\n",
       "         ..., \n",
       "         [ 12.19301987,  22.99743271,  18.88684082],\n",
       "         [ 11.84660912,  27.66487694,  31.53080559],\n",
       "         [  1.45625234,   7.65340614,  36.30850601]],\n",
       "\n",
       "        [[ -6.69076014,   7.09409809,  33.79944229],\n",
       "         [ -3.20938063,  12.97106647,  39.39369202],\n",
       "         [ -0.87970066,  -2.3080008 ,  24.8520546 ],\n",
       "         ..., \n",
       "         [ 12.11437702,  11.57104301,  41.77233887],\n",
       "         [ 16.6821022 ,  15.9099493 ,  20.82740211],\n",
       "         [  6.0095911 ,  28.42125511,  24.60186005]],\n",
       "\n",
       "        ..., \n",
       "        [[-10.11484718,   3.60144639,  10.49164104],\n",
       "         [-28.74271774,  -3.23845863, -10.90115261],\n",
       "         [-15.38578701, -18.74435425,   8.02773285],\n",
       "         ..., \n",
       "         [-20.79760742, -30.4059124 , -11.61053181],\n",
       "         [-12.28290367, -12.508605  , -17.82452583],\n",
       "         [-23.67200851, -28.59186363, -36.05757141]],\n",
       "\n",
       "        [[-10.12826729,  -2.67955589,   3.57038355],\n",
       "         [ -5.7390728 , -10.53736973,  -9.10666084],\n",
       "         [ -5.18830872,   2.05422068,   8.69561291],\n",
       "         ..., \n",
       "         [-25.39966393, -20.6434803 , -29.4226532 ],\n",
       "         [-36.51872253, -30.13332748, -11.0848341 ],\n",
       "         [-38.50114822, -18.65937614, -25.69945908]],\n",
       "\n",
       "        [[-11.55385494,  -8.12104702,   0.36786687],\n",
       "         [-21.97883034, -20.05431938, -10.02203751],\n",
       "         [-21.00663376, -15.7218647 ,   9.99220467],\n",
       "         ..., \n",
       "         [-37.60595322, -14.91892433, -16.47976685],\n",
       "         [-38.52632904, -36.11529541, -14.03088474],\n",
       "         [-27.15143204, -28.65590477, -16.63385391]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = optimizer.minimize(cost_total)\n",
    "sess.run( tf.global_variables_initializer())\n",
    "sess.run(net['input'].assign( INI_NOISE_RATIO* noise_img + (1.-INI_NOISE_RATIO) * content_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 保存先ディレクトリが存在しないときは作成\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION:  0 ,  5.3408e+12\n",
      "ITERATION:  100 ,  6.16613e+10\n",
      "ITERATION:  200 ,  2.52467e+10\n",
      "ITERATION:  300 ,  1.47362e+10\n",
      "ITERATION:  400 ,  1.01176e+10\n",
      "ITERATION:  500 ,  7.45694e+09\n",
      "ITERATION:  600 ,  5.70736e+09\n",
      "ITERATION:  700 ,  4.48629e+09\n",
      "ITERATION:  800 ,  3.60164e+09\n",
      "ITERATION:  900 ,  2.94134e+09\n",
      "ITERATION:  1000 ,  2.43768e+09\n",
      "ITERATION:  1100 ,  2.0538e+09\n",
      "ITERATION:  1200 ,  1.75485e+09\n",
      "ITERATION:  1300 ,  1.5175e+09\n",
      "ITERATION:  1400 ,  2.71715e+09\n",
      "ITERATION:  1500 ,  2.33854e+09\n",
      "ITERATION:  1600 ,  1.17687e+09\n",
      "ITERATION:  1700 ,  9.64381e+08\n",
      "ITERATION:  1800 ,  8.91689e+08\n",
      "ITERATION:  1900 ,  8.97573e+08\n",
      "ITERATION:  2000 ,  7.71974e+08\n",
      "ITERATION:  2100 ,  7.26161e+08\n",
      "ITERATION:  2200 ,  8.8141e+08\n",
      "ITERATION:  2300 ,  7.11507e+08\n",
      "ITERATION:  2400 ,  5.99756e+08\n",
      "ITERATION:  2500 ,  9.85718e+08\n",
      "ITERATION:  2600 ,  5.67326e+08\n",
      "ITERATION:  2700 ,  6.24285e+08\n",
      "ITERATION:  2800 ,  5.5902e+08\n",
      "ITERATION:  2900 ,  4.83905e+08\n",
      "ITERATION:  3000 ,  5.14623e+09\n",
      "ITERATION:  3100 ,  4.81218e+08\n",
      "ITERATION:  3200 ,  4.51296e+08\n",
      "ITERATION:  3300 ,  4.58026e+08\n",
      "ITERATION:  3400 ,  6.34011e+08\n",
      "ITERATION:  3500 ,  4.13978e+08\n",
      "ITERATION:  3600 ,  4.05052e+08\n",
      "ITERATION:  3700 ,  4.52465e+08\n",
      "ITERATION:  3800 ,  4.46993e+08\n",
      "ITERATION:  3900 ,  4.3174e+08\n",
      "ITERATION:  4000 ,  5.91985e+08\n",
      "ITERATION:  4100 ,  3.88244e+08\n",
      "ITERATION:  4200 ,  5.43138e+08\n",
      "ITERATION:  4300 ,  3.48555e+08\n",
      "ITERATION:  4400 ,  3.6474e+08\n",
      "ITERATION:  4500 ,  4.15962e+08\n",
      "ITERATION:  4600 ,  4.21732e+08\n",
      "ITERATION:  4700 ,  3.45596e+08\n",
      "ITERATION:  4800 ,  3.26746e+08\n",
      "ITERATION:  4900 ,  3.45322e+08\n"
     ]
    }
   ],
   "source": [
    "for i in range(ITERATION):\n",
    "    sess.run(train)\n",
    "    # 100回ごとに経過を表示、画像を保存\n",
    "    if i%100 ==0:\n",
    "        result_img = sess.run(net['input'])\n",
    "        print (\"ITERATION: \",i,\", \",sess.run(cost_total))\n",
    "        write_image(os.path.join(OUTPUT_DIR,'%s.png'%(str(i).zfill(4))),result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_image(os.path.join(OUTPUT_DIR,OUTPUT_IMG),result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
